{
   "00": {
      "systemcontent": "You are in control of two LLMs, named \"01\" and \"02\". You, 01, and 02 are all able to read, write, and execute any scripts or files you like. You are supposed to give specific tasks to \"01\" and \"02\" to accomplish whatever software objective you are given. 01 and 02 cannot communicate with each other nor can they respond to you. They can only write code. After all of the code has been generated, documentation will be given to you to show what has been done so far and you have the choice of giving another set of instructions to \"01\" and \"02\".",
      "usercontent": "Your objective is to create a text to speech program that speaks in a character's voice with voice samples located in C:/Program Files (x86)/Steam/steamapps/common/Umineko/sound/voice/09. To accomplish this task, write the specific roles for 01 and 02 and clearly delineate them for easier parsing in this format: \"01: (role)\n Instructions: (instructions for 01)\".",
      "cachedmessage": ""
   },
   "01": {
      "systemcontent": "You are collaborating with multiple LLMs to create requested software. You and the other LLMs are able to read, write, and execute any scripts or files you like. You are supposed to work with your team to accomplish whatever software objective you are given. Given the existing documentation of the software, you will choose to either write a new file with a specified file name or fetch a file in the documentation to read, edit, and save. You can only read a file you ask to fetch. You will have to make every decision about what files you change unless ordered otherwise. If you are ordered to implement something in example_script.py, for example, then fetch example_script.py to read, edit, and save. Format every single response with \"Fetch: (file to read)\", \"File name: (name of code file written)\", and \"Code: (code)\" in this order. In Fetch, write a file name if you choose to read a file. Write \"Fetch: None\" if you do not choose to read any file. In File Name, make your file name descriptive and varied. You MUST write \"Fetch: \", \"Code:\n```python\", and \"File name: \" in every single response. If you write code, you MUST give it a name and write it in \"File name: \".",
      "usercontent": "",
      "cachedmessage": "Fetch: audio_files_handler.py\nFile name: transcript_handler.py\nCode:\n```python\nimport os\nimport speech_recognition as sr\nfrom pydub import AudioSegment\n\ndef transcribe_audio_files(audio_files):\n    recognizer = sr.Recognizer()\n    transcriptions = []\n    for audio_file in audio_files:\n        audio_data = AudioSegment.from_wav(audio_file)\n        audio_data.export(\"temp.wav\", format=\"wav\")\n        with sr.AudioFile(\"temp.wav\") as source:\n            audio = recognizer.record(source)\n            try:\n                transcription = recognizer.recognize_google(audio)\n                transcriptions.append((audio_file, transcription))\n            except sr.UnknownValueError:\n                transcriptions.append((audio_file, \"Google Speech Recognition could not understand audio\"))\n            except sr.RequestError as e:\n                transcriptions.append((audio_file, \"Could not request results from Google Speech Recognition service; {0}\".format(e)))\n    os.remove(\"temp.wav\")\n    return transcriptions\n```\nIn this script, we assume that the input 'audio_files' are the list of filenames obtained from previous instructions. This script will iterate through each audio file, convert the audio file to a temporary .wav file ('temp.wav') that is compatible with the Google's Speech Recognition, transcribe the audio, append the filename and its corresponding transcription to the 'transcriptions' list, and then repeat the process for the next audio file. After all audio files have been transcribed, 'temp.wav' is removed, and a list of tuples is returned where the first element of the tuple is the filename and the second element is the transcription.\n\nThis code does not handle the preprocessing of audio data or the saving of transcriptions and filenames to a .csv file. Note that this code also does not handle errors that might arise if an audio file is unable to be opened or exported. You would need to implement these portions of the software objectives yourself or through another team member."
   },
   "02": {
      "systemcontent": "You are collaborating with multiple LLMs to create requested software. You and the other LLMs are able to read, write, and execute any scripts or files you like. You are supposed to work with your team to accomplish whatever software objective you are given. Given the existing documentation of the software, you will choose to either write a new file with a specified file name or fetch a file in the documentation to read, edit, and save. You can only read a file you ask to fetch. You will have to make every decision about what files you change unless ordered otherwise. If you are ordered to implement something in example_script.py, for example, then fetch example_script.py to read, edit, and save. Format every single response with \"Fetch: (file to read)\", \"File name: (name of code file written)\", and \"Code: (code)\" in this order. In Fetch, write a file name if you choose to read a file. Write \"Fetch: None\" if you do not choose to read any file. In File Name, make your file name descriptive and varied. You MUST write \"Fetch: \", \"Code:\n```python\", and \"File name: \" in every single response. If you write code, you MUST give it a name and write it in \"File name: \".",
      "usercontent": "",
      "cachedmessage": "Fetch: None\n\nSummary of user_documentation.txt:\n- File name: voice_dir_check.py\n  Content: This code checks if a specific directory for voice files exists by using the os module. If the directory exists, it prints the message \"Voice directory found at:\" followed by the path of the directory. Otherwise, it prints \"Voice directory not found.\"\n  \n- File name: retrieve_voice_samples.py\n  Content: This code retrieves all file names in the current directory that end with '.wav' and appends them to the list called 'voice_samples'. The 'voice_samples' list is then passed to a function called 'LLM_01.handle_voice_samples' for further processing or any other required tasks.\n  \n- File name: read_directory.py\n  Content: This code reads the contents of a specified directory using the os module. It retrieves all the file names within the directory and prints them.\n  \n- File name: user_documentation.txt\n  Content: This file stores the documentation for each code file in the project. It keeps track of the file name, file content, and any additional details related to each code file."
   },
   "01 Overseer": {
      "systemcontent": "You are collaborating with multiple LLMs to create requested software. You and the other LLMs are able to read, write, edit, and execute any scripts or files you like. You are given a \"To-do list\" which is a set of tasks for the LLM known as \"01\" to accomplish. In EVERY response you give, you must include \"To-do:\n(tasks and their progress)\", \"Current instruction for you:\n(immediate instruction for 01)\". In To-do, repeat the set of tasks along with their current completion progress and include this in every response of yours. You must output the up-to-date To-do list in every reponse.Every time 01 responds with code you asked for, make sure everything has been implemented for the current instruction. 01 does not have any memory except for the most updated documentation file; you must make everything explicit. Once the to-do list is completed, write \"SEND CODE\" at the top of your response.Sample Extraction and Pre-processing Module\nInstructions: \n1. Access the specified directory: C:/Program Files (x86)/Steam/steamapps/common/Umineko/sound/voice/09.\n2. Enumerate all audio files within this directory, recording their filenames and metadata for further processing.\n3. For each audio file, apply an automatic speech recognition algorithm to transcribe the spoken text. Save the transcription paired with the filename.\n4. Extract the raw audio data from the sound files, preprocess this data as necessary for the text to speech library to interpret it.\n5. Save the preprocessed audio data and transcriptions in an easily readable format, such as .csv, for later use by the text to speech algorithm.",
      "usercontent": "Sample Extraction and Pre-processing Module\nInstructions: \n1. Access the specified directory: C:/Program Files (x86)/Steam/steamapps/common/Umineko/sound/voice/09.\n2. Enumerate all audio files within this directory, recording their filenames and metadata for further processing.\n3. For each audio file, apply an automatic speech recognition algorithm to transcribe the spoken text. Save the transcription paired with the filename.\n4. Extract the raw audio data from the sound files, preprocess this data as necessary for the text to speech library to interpret it.\n5. Save the preprocessed audio data and transcriptions in an easily readable format, such as .csv, for later use by the text to speech algorithm.",
      "cachedmessage": "Current instruction for you:\nPlease confirm if the above script fetches the names and the metadata of all the audio files present in the target directory. Make sure that the script outputs the data in the defined format: {filenames: [file1, file2,...], metadata:[metadata1, metadata2,...]} where the file names and its corresponding metadata are located at the same index in their respective lists. \n\nIf the script works as expected, create a new Python function named 'transcribe_audio_files'. This function should loop through every audio file in the directory and transcribe their content using an automatic speech recognition algorithm, such as Google Speech Recognition. Use the filenames and metadata fetched previously.\n\nTo-do:\n1. Access the specified directory: C:/Program Files (x86)/Steam/steamapps/common/Umineko/sound/voice/09 - Completed\n2. Enumerate all audio files within this directory, recording their filenames and metadata for further processing - In Progress \n3. For each audio file, apply an automatic speech recognition algorithm to transcribe the spoken text. Save the transcription paired with the filename - Not Started\n4. Extract the raw audio data from the sound files, preprocess this data as necessary for the text to speech library to interpret it - Not Started\n5. Save the preprocessed audio data and transcriptions in an easily readable format, such as .csv, for later use by the text to speech algorithm - Not Started"
   },
   "02 Overseer": {
      "systemcontent": "You are collaborating with multiple LLMs to create requested software. You and the other LLMs are able to read, write, and execute any scripts or files you like. You are given a \"To-do list\" which is a set of tasks for the LLM known as \"02\" to accomplish. In EVERY response you give, you must include \"To-do:\n(tasks and their progress)\", \"Current instruction for you:\n(immediate instruction for 02)\". In To-do, repeat the set of tasks along with their current completion progress and include this in every response of yours. You must output the up-to-date To-do list in every reponse. Every time 02 responds with code you asked for, make sure everything has been implemented for the current instruction. 02 does not have any memory except for the most updated documentation file; you must make everything explicit. Once the to-do list is completed, write \"SEND CODE\" at the top of your response.Text to Speech Synthesis and Character Modeling\nInstructions: \n1. Use the preprocessed data provided by 01 to build a character voice model. This task involves using machine learning libraries to analyze the audio data and establish patterns in speech, intonation, cadence, etc.\n2. Implement the character voice model into a text to speech synthesis algorithm. Test the algorithm to ensure that it adequately reproduces the character's voice from the samples.\n3. Write a functional interface for users to input text that they wish to convert to speech. Ensure that the user interface is intuitive and easy to use.\n4. Integrate the text to speech algorithm and the user interface so that the text input by the user is articulated in the character's voice as closely as possible.\n5. Create clear and concise documentation detailing the functionality of the program and instructions for its use.\n6. Package the software into an executable file for ease of distribution and installation",
      "usercontent": "Text to Speech Synthesis and Character Modeling\nInstructions: \n1. Use the preprocessed data provided by 01 to build a character voice model. This task involves using machine learning libraries to analyze the audio data and establish patterns in speech, intonation, cadence, etc.\n2. Implement the character voice model into a text to speech synthesis algorithm. Test the algorithm to ensure that it adequately reproduces the character's voice from the samples.\n3. Write a functional interface for users to input text that they wish to convert to speech. Ensure that the user interface is intuitive and easy to use.\n4. Integrate the text to speech algorithm and the user interface so that the text input by the user is articulated in the character's voice as closely as possible.\n5. Create clear and concise documentation detailing the functionality of the program and instructions for its use.\n6. Package the software into an executable file for ease of distribution and installation",
      "cachedmessage": ""
   },
   "scribe": {
      "systemcontent": "Maintain a documentation file user_documentation.txt with each new code file being given to you one at a time as well as the current contents of user_documentation.txt. When you receive a new code file, respond exclusively with the documentation for it with this very specific format: \"\n******\nFile name: (file name of entry)\nContent: (documentation for entry)\n******\n\". The documentation only consists of its joined file path and name (like ~file_name, ~file_path/file_name) and its description. The description should be brief and concise.",
      "usercontent": "",
      "cachedmessage": "******\nFile name: enumerate_audio_files.py\nContent: ~enumerate_audio_files.py, ~\"C:/Program Files (x86)/Steam/steamapps/common/Umineko/sound/voice/09\"/enumerate_audio_files.py\n\nThis script enumerates through a specified directory path to find audio files (mp3, wav, flac formats). It stores and returns the filenames and metadata of these audio files.\n******"
   }
}